---
title: Bayesian approach for model-based prediction of sampling variance of estimated spatial mean, assuming a lognormal distribution for the data
author: "Dick Brus and siegfried Hofman"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

R packages are loaded. 

```{r}
library(e1071)
library(BayesianTools)
library(sp)
library(gstat)
library(mvtnorm)
library(spcosa)
library(rgdal)
library(ggplot2)
```

Compute summary statistics of the data per field.

```{r}
fields <- c(1,2,3,4,5,6,13,14,15,16,17,18,19,20,30,35)
m <- cv <- skew <- numeric(length=length(fields))
r <- 1
for (f in fields) {
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  #replace zeroes for N by reprting limit
  ids <- which(df$N==0)
  if(length(ids)>0) {
    df$N[ids] <- 0.5
  }
  m[r] <- mean(df$N)
  cv[r] <- sqrt(var(df$N))/m[r]
  skew[r] <- skewness(df$N)
  r <- r+1
}
df <- data.frame(fields,m,cv,skew)
ord <- order(df$cv)
df[ord,]
```

Make Q-Qplots to check normality of N.

```{r}
fields <- c(1,2,3,4,5,6,13,14,15,16,17,18,19,20,30,35)
pvalues <- minimumN <- numeric(length=length(fields))
i <- 1
for (f in fields) {
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  minimumN[i] <- min(df$N)
  #replace zeroes for N by reprting limit
  ids <- which(df$N==0)
  if(length(ids)>0) {
    df$N[ids] <- 0.5
  }
  name <- paste0("Field",f)
  qqnorm(df$N, main=name)
  qqline(df$N)
  out <- shapiro.test(df$N)
  pvalues[i] <- out$p.value
  i <- i+1
}
df <- data.frame(fields,pvalues)
print(df)
```

## MCMC sampling


The log likelihood function is defined, assuming a normal distribution of the logtransformed data. The variance of the measurement error is added to the diagonal of the covariance matrix, so that the sampled variogram parameters are the variogram parameters of errorless measurements of logN. This is needed because in the evaluated sampling design the soil samples are not analyzed separately. The soil samples are bulked into a composite sample, which is analyzed.

```{r likelihood}
ll <-function(thetas) {
  sill <- 1/thetas[1]
  nugget <- thetas[2]*sill
  psill <- sill-nugget
  C <- variogramLine(
    vgm(model=model,psill=psill,range=thetas[3],nugget=nugget),dist_vector=D,covariance=TRUE)
  diag(C) <- diag(C)+varlaberror
  Cinv <- chol2inv(chol(C))
  XC <- crossprod(X, Cinv)
  XCz <- XC %*% z
  XCX <- XC %*% X
  betahat <- solve(XCX , XCz)
  mu <- as.numeric(X%*%betahat)
  logLik <- dmvnorm(x=z, mean=mu, sigma = C, log = T)
  return(logLik)
}
```

Initially, the variogram of logN is estimated by maximum likelihood. An exponential variogram model is assumed. The ML estimates are used as initial values in MCMC sampling. In the Bayesian approach, I use a uniform prior for the inverse of the sill parameter, $\lambda=1/\sigma^2$, with a lower bound of 1e-6 and an upper bound of 1. For the distance parameter $\phi$ of the exponential variogram a uniform prior is assumed, with a lower bound of 1e-6 and an upper bound equal to three times the maximum distance in the dataset. For the relative nugget, $\tau^2/\sigma^2$, a uniform prior is assumed with a lower bound of 0 and an upper bound of 1.



```{r MCMCsampling, eval=F, messages=FALSE, warning=FALSE}
for (f in fields) {
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  ids <- which(df$N==0)
  if(length(ids)>0) {
    df$N[ids] <- 0.5
  }
  #recompute logN, take natural logs
  df$logN <- log(df$N)

  df$Easting  <- df$Easting - min(df$Easting)
  df$Northing <- df$Northing - min(df$Northing)

#compute variance of laborary measurement error (within lab) on log-scale!
  varlaberror <- 0.064^2

# compute matrix with Euclidian distances between sampling points
  coordinates(df) <- ~Easting+Northing
  D <- spDists(df)

  lambda.ini <- 1/var(df$logN) #initial value for inverse of sill variance sigmasq
  tausqrel.ini <-  0.5 #initial value for tausq/sigmasq
  phi.ini <- round(mean(D),0)
  pars <- c(lambda.ini,tausqrel.ini,phi.ini)

  df <- as(df,"data.frame")
  X <- matrix(1 , nrow(df) , 1)
  z <- df$logN
  model <- "Exp"
  phimax <- round(3*max(D),0) 
  vgML <- optim(pars, ll, control = list(fnscale = -1), 
              method="L-BFGS-B", lower=c(1e-6,0,1e-6), upper=c(1000,1,phimax))
  lambda.ini <- vgML$par[1]
  tausqrel.ini <- vgML$par[2]
  phi.ini <- vgML$par[3]

  priors <- createUniformPrior(lower=c(1e-6,0,1e-6), upper=c(1000,1,phimax))
  setup <- createBayesianSetup(likelihood=ll,prior=priors,
                             best=c(lambda.ini,tausqrel.ini,phi.ini), 
                             names=c("lambda","tausqrel","phi"))
  set.seed(314)
  DEzs.out <- runMCMC(setup,sampler="DEzs")

  mcmcsam <- getSample(DEzs.out,start=1000,numSamples=1000)
  mcmcsample <-data.frame(mcmcsam)
  outputfilename <- paste0("MCMCsample",f,"_logN",".csv")
  write.csv(file=outputfilename,mcmcsample)
}
```

Compute standard deviation, coeffcient of variation, P10, P50 and P90 of the estimated variogram parameters, and the correlation matrix.

```{r}
qnt.sill <- qnt.nugget <- qnt.range <- qnt.relnugget <- Cor <- matrix(nrow=length(fields),ncol=3)
m.sill <- m.nugget <- m.relnugget <- m.range <-
numeric(length=length(fields)) 
sd.sill <- sd.nugget <- sd.relnugget <- sd.range <-
numeric(length=length(fields)) 
cv.sill <- cv.nugget <- cv.relnugget <- cv.range <- numeric(length=length(fields)) 
r <- 1
for (f in fields) {
  filename <- paste0("MCMCsample",f,"_logN.csv")
  MCMCsample <- read.csv(file=filename,header=TRUE)
  sill <- 1/MCMCsample$lambda
  qnt.sill[r,] <- quantile(sill,c(0.1,0.5,0.9))
  m.sill[r] <- mean(sill)
  sd.sill[r] <- sqrt(var(sill))
  cv.sill[r] <- sqrt(var(sill))/mean(sill)
  relnugget <- MCMCsample$tausqrel
  qnt.relnugget[r,] <- quantile(relnugget,c(0.1,0.5,0.9))
  m.relnugget[r] <- mean(relnugget)
  sd.relnugget[r] <- sqrt(var(relnugget))
  cv.relnugget[r] <- sqrt(var(relnugget))/mean(relnugget)
  nugget <- 1/MCMCsample$lambda*MCMCsample$tausqrel
  qnt.nugget[r,] <- quantile(nugget,c(0.1,0.5,0.9))
  m.nugget[r] <- mean(nugget)
  sd.nugget[r] <- sqrt(var(nugget))
  cv.nugget[r] <- sqrt(var(nugget))/mean(nugget)
  range <- MCMCsample$phi
  qnt.range[r,] <- quantile(range,c(0.1,0.5,0.9))
  m.range[r] <- mean(range)
  sd.range[r] <- sqrt(var(range))
  cv.range[r] <- sqrt(var(range))/mean(range)
  df <- data.frame(sill,nugget,phi=range)
  corr <- cor(df)
  Cor[r,] <- corr[lower.tri(corr)]
  r <- r+1
}
(df <- data.frame(fields,m.relnugget,sd.relnugget,m.sill,sd.sill,m.range,sd.range))
```


The first 20 sampled variograms are plotted.

```{r}
for (f in fields) {
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  df$Easting  <- df$Easting - min(df$Easting)
  df$Northing <- df$Northing - min(df$Northing)
  coordinates(df) <- ~Easting+Northing
  D <- spDists(df)
  maxD <- floor(3*max(D)/10)*10
  d <- seq(from=1,to=maxD,by=1)

  filename <- paste0("MCMCsample",f,"_logN.csv")
  MCMCsample <- read.csv(file=filename,header=TRUE)
  semivar <- matrix(nrow=length(d),ncol=20)
  for (i in 1:20) {
    sill <- 1/MCMCsample$lambda[i]
    nugget <- MCMCsample$tausqrel[i]*sill
    psill <- sill-nugget
    phi <- MCMCsample$phi[i]
    g <- variogramLine(
      vgm(model="Exp",psill=psill,range=phi,nugget=nugget),dist_vector=d)
    semivar[,i] <- g$gamma
  }
  df <- data.frame(d=d,semivar)

  filename <- paste0("Variograms_logN_perceel",f,".pdf")
  title <- paste0("Field ",f)
  pdf(file = filename, width = 6, height = 4)
  print(ggplot(df)+
    geom_line(mapping=aes(x=d,y=X1))+
    geom_line(mapping=aes(x=d,y=X2))+
    geom_line(mapping=aes(x=d,y=X3))+
    geom_line(mapping=aes(x=d,y=X4))+
    geom_line(mapping=aes(x=d,y=X5))+
    geom_line(mapping=aes(x=d,y=X6))+
    geom_line(mapping=aes(x=d,y=X7))+
    geom_line(mapping=aes(x=d,y=X8))+
    geom_line(mapping=aes(x=d,y=X9))+
    geom_line(mapping=aes(x=d,y=X10))+
    geom_line(mapping=aes(x=d,y=X11))+
    geom_line(mapping=aes(x=d,y=X12))+
    geom_line(mapping=aes(x=d,y=X13))+
    geom_line(mapping=aes(x=d,y=X14))+
    geom_line(mapping=aes(x=d,y=X15))+
    geom_line(mapping=aes(x=d,y=X16))+
    geom_line(mapping=aes(x=d,y=X17))+
    geom_line(mapping=aes(x=d,y=X18))+
    geom_line(mapping=aes(x=d,y=X19))+
    geom_line(mapping=aes(x=d,y=X20))+
    scale_x_continuous(name = "Distance (m)",) +
    scale_y_continuous(name = "Semivariance",limits=c(0,NA))+
    ggtitle(title) +
    theme(plot.title = element_text(hjust=0.5)))
  dev.off()
}
```

Estimate with each sampled variogram the mean of logN of a field, $\mu$, by the Best Linear Unbiased Estimator.

```{r}
nMCMC <- 100
mu <- matrix(nrow=length(fields),ncol=nMCMC)
r <- 1
for (f in fields) {
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  df$Easting  <- df$Easting - min(df$Easting)
  df$Northing <- df$Northing - min(df$Northing)
  ids <- which(df$N==0)
  if(length(ids)>0) {
    df$N[ids] <- 0.5
  }

  #recompute logN, take natural logs
  df$logN <- log(df$N)
  coordinates(df) <- ~Easting+Northing
  d.sample <- spDists(df)
  
  # read MCMC sample of variogram parameters
  filename <- paste0("MCMCsample",f,"_logN.csv")
  MCMCsample <- read.csv(file=filename,header=TRUE)

  set.seed(314)
  for (i in 1:nMCMC) {
    sill <- 1/MCMCsample$lambda[i]
    range <- MCMCsample$phi[i]
    nugget <- MCMCsample$tausqrel[i]*sill
    psill <- sill - nugget
    # Estimate mean on logscale with BLUE. Add varlaberror to diagonal of C
    C.sample <-  variogramLine(object=vgm(model="Exp", nugget=nugget,
                                          psill=psill, range=range), dist_vector=d.sample, covariance=TRUE)
    varlaberror <- 0.064^2
    diag(C.sample) <- diag(C.sample) + varlaberror
    Cinv <- chol2inv(chol(C.sample))
    X <- matrix(1 , nrow(df) , 1)
    z <- df$logN
    XC <- crossprod(X, Cinv)
    XCz <- XC %*% z
    XCX <- XC %*% X
    mu[r,i] <- as.numeric(solve(XCX , XCz))
  }
  r <- r+1
}
```

## Prediction of sampling variance

The evaluated sampling design is stratified simple random sampling, using compact geographical strata of equal size and one point per stratum. Evaluated sample sizes are $5, 10, \cdots , 50$.

As a first step for each field the geostrata are computed, for all sample sizes.

```{r geostratification, eval=F}
nStrata <- c(5,10,15,20,25,30,35,40,45,50)

# set number of nodes of discretisation grid
Ngrd <- 2000
set.seed(314)

for (f in fields) {
  # read field of interest
  filename <- paste0("perceel",f)
  shpField <- readOGR(dsn = "shapefiles", layer = filename)
  # remove projection attributes
  proj4string(shpField) <- NA_character_
  # construct discretisation grid
  mygrid <- spsample(shpField,type="regular",n=Ngrd,offset=c(0.5,0.5))
  gridded(mygrid) <- TRUE
  for (L in nStrata) {
    mygeostrata <- stratify(mygrid,nStrata = L, equalArea=TRUE, nTry=10)
    mygeostrata<-as(mygeostrata, "data.frame")
    filename <- paste0("Geostrata_perceel",f,"_",L,".RData")
    save(mygeostrata, file=filename)
  } 
}
```

The next step is to simulate with each of the sampled variograms a large number of fields. This is done by Cholesky decomposition of the covariance matrix. Each simulated field is used to compute the variance of the simulated values within the geostrata. These stratum variances are used to compute the sampling variance of the estimated mean.

I used 100 sampled variograms, and for each variogram I simulated 100 fields.

Besides for each variogram and each simulated field per variogram the poulation variance of the simulated values is computed. This population variance can be used to compute the sampling variance of the estimated eman for simple random sampling. 

```{r simulatevariances, eval=F}
# set number of MCMC samples to use
nMCMC <- 100

# set number of fields to be simulated
nsim <- 100

# start for-loop over all fields
r <- 1
for (f in fields) {
  print(f)
  #load fle with geostrata to extract discretisation grid
  filename <- paste0("Geostrata_perceel",f,"_5",".RData")
  load(file=filename)
  mygrid <- mygeostrata[,c(2,3)]
  coordinates(mygrid) <- ~x1+x2

  # read MCMC sample of variogram parameters
  filename <- paste0("MCMCsample",f,"_logN.csv")
  MCMCsample <- read.csv(file=filename,header=TRUE)

  # array for storing the simulated variances of the estimated mean
  V  <- array(dim=c(length(nStrata),nMCMC,nsim))
  S2 <- matrix(nrow=nMCMC,ncol=nsim) #population variance
  
  set.seed(314)
  for (i in 1:nMCMC) {
    D <- spDists(mygrid)
    sill <- 1/MCMCsample$lambda[i]
    range <- MCMCsample$phi[i]
    nugget <- MCMCsample$tausqrel[i]*sill
    psill <- sill - nugget
    
    # Cholesky decomposition of covariance matrix
    C <-  variogramLine(object=vgm(model="Exp",nugget=nugget,psill=psill,
                                   range=range),
                        dist_vector=D, covariance=TRUE)
    Upper<-chol(C)
    for (j in 1:nsim) {
      # simulate random numbers from standard normal distribution
      G<-rnorm(n=nrow(C),0,1)
      zsim <- crossprod(Upper,G)
      # add BLUE of mean of field
      zsim <- zsim+mu[r,i]
      # backtransform
      ysim <- exp(zsim)
      # compute population variance (needed to compute variance of mean estimated by simple random sampling)
      S2[i,j] <- as.vector(var(ysim))
      h <- 1
      for (L in nStrata) {
        filename <- paste0("Geostrata_perceel",f,"_",L,".RData")
        load(file=filename)
        S2h <- tapply(ysim,INDEX=as.factor(mygeostrata$stratumId),FUN=var)
        V[h,i,j] <- 1/L^2*sum(S2h)
        h <- h+1
      }
    }
  }
  filename <- paste0("Variances_wlt_perceel",f,".RData")
  save(V,S2,file=filename)
  r <- r+1
}
```

For each sample size the mean and P90 of the 100 x 100 sampling variances are computed. Besides the variance over the 100 sampled variograms of the  average sampling variance, averaged over the 100 fields, is computed (VmcmcExiV.STSI), as well as the average over the 100 sampled variograms of the variance of the sampling variance over the 100 fields (EmcmcVxiV.STSI).

```{r}
EmcmcExiV.STSI <- EmcmcVxiV.STSI <- VmcmcExiV.STSI  <- P90V.STSI <- P50V.STSI <- matrix(nrow=length(fields),ncol=length(nStrata))
r <- 1
for (f in fields) {
  filename <- paste0("Variances_wlt_perceel",f,".RData")
  load(filename)

  ExiV.STSI <- VxiV.STSI <- matrix(nrow=length(nStrata),ncol=nMCMC)
  for (i in 1:length(nStrata)) {
    V.L <- V[i,,]
  # compute for each sampled variogram the mean and variance of the sampling variances over the nsim fields
    ExiV.STSI[i,] <- apply(V.L,MARGIN=1,FUN=mean)
    VxiV.STSI[i,] <- apply(V.L,MARGIN=1,FUN=var)
    P50V.STSI[r,i] <- quantile(V.L,0.5)
    P90V.STSI[r,i] <- quantile(V.L,0.9)
  }
  # compute average over all sampled variograms of conditional ExiV.STSI (conditional on variogram) 
  EmcmcExiV.STSI[r,] <- apply(ExiV.STSI,MARGIN=1,FUN=mean)
  # compute variance over all sampled variograms of conditional ExiV.STSI (conditional on variogram)
  VmcmcExiV.STSI[r,] <- apply(ExiV.STSI,MARGIN=1,FUN=var)
  # compute average over all sampled variograms of conditional VxiV.STSI (conditional on variogram)
  EmcmcVxiV.STSI[r,] <- apply(VxiV.STSI,MARGIN=1,FUN=mean)
  
  r <- r+1
}
```

Plot the predicted sampling variance against sample size (number of geostrata).

```{r}
r <- 1
for (f in fields) {
  df <- data.frame(L=nStrata,mean=EmcmcExiV.STSI[r,],P50=P50V.STSI[r,],P90=P90V.STSI[r,])
  filename <- paste0("SamplingVariance_wlt_perceel",f,".pdf")
  title <- paste0("Field ",f)
  pdf(file = filename, width = 6, height = 4)
  print(ggplot(df)+
    geom_point(mapping=aes(x=L,y=mean),size=2)+
    geom_point(mapping=aes(x=L,y=P50),colour="red",size=2)+
    geom_point(mapping=aes(x=L,y=P90),colour="green",size=2)+
    scale_x_continuous(name = "Sample size",) +
    scale_y_continuous(name = "Sampling variance",limits=c(0,NA))+
    ggtitle(title) +
    theme(plot.title = element_text(hjust=0.5)))
  dev.off()
  r <- r+1
}
```

Plot the two components of the variance of the sampling variance (over repeated MCMC sampling and repeated simulation of fields) against the sample size.

```{r}
r <- 1
for (f in fields) {
  df <- data.frame(L=nStrata,VmcmcExi=VmcmcExiV.STSI[r,],EmcmcVxi=EmcmcVxiV.STSI[r,])
  filename <- paste0("VarianceComponents_wlt_perceel",f,".pdf")
  title <- paste0("Field ",f)
  pdf(file = filename, width = 6, height = 4)
  print(ggplot(df)+
    geom_point(mapping=aes(x=L,y=VmcmcExi),colour="red")+
    geom_point(mapping=aes(x=L,y=EmcmcVxi))+
    scale_x_continuous(name = "Sample size",) +
    scale_y_continuous(name = "Variance component",limits=c(0,NA))+
    ggtitle(title) +
    theme(plot.title = element_text(hjust=0.5)))
  dev.off()
  r <- r+1
}
```

These figures clearly show that the contribution of the uncertainty about the variogram parameters (red dots in figures, VmcmcExi) is much larger than the contribution due to uncertainty about the stratum variances given a variogram. For all fields, the second variance component is negligible for sample sizes of 10 and larger.

Compute the mean and P90 of the sampling variance for simple random sampling

```{r}
EmcmcExiV.SI <- P50V.SI <- P90V.SI <- matrix(nrow=length(fields),ncol=length(nStrata))
r <- 1
for (f in fields) {
  filename <- paste0("Variances_wlt_perceel",f,".RData")
  load(filename)
  for (i in 1:length(nStrata)) {
    n <- matrix(data=nStrata[i],nrow=nrow(S2),ncol=ncol(S2))
    V.SI <- S2/n
    EmcmcExiV.SI[r,i] <- mean(V.SI)
    P50V.SI[r,i] <- quantile(V.SI,0.5)
    P90V.SI[r,i] <- quantile(V.SI,0.9)
  }
  r <- r+1
}
```


Make plot of stratification effect based on the median, as a function of the sample size

```{r, out.width='50%',fig.asp=.5, fig.show='hold'}
strateff.wlt = t(P50V.SI/P50V.STSI)
#replace strateff for fields 1, 5, 6 and 20 by stratef computed with normal distribution
load("StratificationEffect_normal.RData")
strateff.wlt[,c(1,5,6,14)] <- strateff[,c(1,5,6,14)]
df <- data.frame(n=nStrata,strateff.wlt)
pdf(file = "Stratificationeffect_allflds.pdf", width = 6, height = 4)
ggplot(df)+
  geom_line(mapping=aes(x=nStrata,y=X1,colour="red"))+
  geom_line(mapping=aes(x=nStrata,y=X2))+
  geom_line(mapping=aes(x=nStrata,y=X3))+
  geom_line(mapping=aes(x=nStrata,y=X4))+
  geom_line(mapping=aes(x=nStrata,y=X5,colour="red"))+
  geom_line(mapping=aes(x=nStrata,y=X6,colour="red"))+
  geom_line(mapping=aes(x=nStrata,y=X7))+
  geom_line(mapping=aes(x=nStrata,y=X8))+
  geom_line(mapping=aes(x=nStrata,y=X9))+
  geom_line(mapping=aes(x=nStrata,y=X10))+
  geom_line(mapping=aes(x=nStrata,y=X11))+
  geom_line(mapping=aes(x=nStrata,y=X12))+
  geom_line(mapping=aes(x=nStrata,y=X13))+
  geom_line(mapping=aes(x=nStrata,y=X14,colour="red"))+
  geom_line(mapping=aes(x=nStrata,y=X15))+
  geom_line(mapping=aes(x=nStrata,y=X16))+
  scale_x_continuous(name = "Sample size",) +
  scale_y_continuous(name = "Stratification effect",limits=c(1,NA))+
  theme(legend.position = "none") 
dev.off()

```



```{r}
r <- 1
U <- U.P50 <- U.P90 <- matrix(nrow=length(fields),ncol=length(nStrata))
for (f in fields){
  filename <- paste0("Perceel",f,".csv")
  df <- read.csv(filename,header = FALSE)
  names(df) <- c("Easting","Northing","N","logN")
  meanz <- mean(df$N)
  varlaberror <- (meanz * 0.064)^2
  sdtot <- sqrt(EmcmcExiV.STSI[r,] + varlaberror)
  U[r,] <- (2*sdtot/meanz)*100
  sdtot <- sqrt(P50V.STSI[r,] + varlaberror)
  U.P50[r,] <- (2*sdtot/meanz)*100
  sdtot <- sqrt(P90V.STSI[r,] + varlaberror)
  U.P90[r,] <- (2*sdtot/meanz)*100
  r <- r+1
}
```

Plot $U$ against sample size.

```{r, out.width='50%',fig.asp=.5, fig.show='hold'}
r <- 1
for (f in fields) {
  df <- data.frame(L=nStrata,U = U[r,], P50U = U.P50[r,], P90U = U.P90[r,])
  filename <- paste0("U_wlt_perceel",f,".pdf")
  title <- paste0("Field ",f)
  pdf(file = filename, width = 6, height = 4)
  print(ggplot(df)+
#    geom_point(mapping=aes(x=L,y=U))+
    geom_point(mapping=aes(x=L,y=P50U,colour="red"))+
    geom_point(mapping=aes(x=L,y=P90U),colour="green")+
    scale_x_continuous(name = "Sample size") +
    scale_y_continuous(name = "U%",limits=c(0,100))+
    theme(legend.position = "none")+ 
    ggtitle(title) +
    theme(plot.title = element_text(hjust=0.5)))
  dev.off()
  r <- r+1
}
```

Required sample sizes are computed for a threshold of 50\% for $U$.

```{r}
r <- 1
nreq <- nreqP50 <- nreqP90 <- numeric(length=length(fields))
for (f in fields){
  nreq[r] <- ceiling(approx(x=U[r,],y=nStrata,xout=50,yleft=51,yright=4)$y)
  nreqP50[r] <- ceiling(approx(x=U.P50[r,],y=nStrata,xout=50,yleft=51,yright=4)$y)
  nreqP90[r] <- ceiling(approx(x=U.P90[r,],y=nStrata,xout=50,yleft=51,yright=4)$y)
  r <- r+1
}

df <- data.frame(field=fields,nreq=nreq,nreqP50=nreqP50,nreqP90=nreqP90)
df$nreq <- as.character(df$nreq)
df$nreqP50 <- as.character(df$nreqP50)
df$nreqP90 <- as.character(df$nreqP90)
df$nreq[df$nreq==4] <- "<5"
df$nreq[df$nreq==51] <- ">50"
df$nreqP50[df$nreqP50==4] <- "<5"
df$nreqP50[df$nreqP50==51] <- ">50"
df$nreqP90[df$nreqP90==4] <- "<5"
df$nreqP90[df$nreqP90==51] <- ">50"
(df)
```
